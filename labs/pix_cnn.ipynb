{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pix_cnn_alan.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/janchorowski/JSALT2019_tutorials/blob/master/labs/pix_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TW0TA4Kfs_ev",
        "colab_type": "text"
      },
      "source": [
        "# PixelCNN Lab Session\n",
        "\n",
        "The following exercises will make you familiar with simple variants of PixelCNN. For the details consult the paper:\n",
        "\n",
        "[van den Oord et al., Pixel Recurrent Neural Networks](http://proceedings.mlr.press/v48/oord16.pdf)\n",
        "\n",
        "[van den Oord et al., Conditional image generation with pixelcnn decoders](https://papers.nips.cc/paper/6527-conditional-image-generation-with-pixelcnn-decoders.pdf)\n",
        "\n",
        "Try not to spend too much time on a single task; if you find yourself stuck, ask for help!\n",
        "\n",
        "**Make sure to set `Runtime->Change runtime type` to Python 3 and GPU.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiBttyWo5-r1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O65LlKGN6Cna",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q gdown httpimport\n",
        "![ -e cifar.npz ] || gdown 'https://drive.google.com/uc?id=1oBzZdtg2zNTPGhbRy6DQ_wrf5L5OAhNR' -O cifar.npz\n",
        "![ -e mnist.npz ] || gdown 'https://drive.google.com/uc?id=1QPaC3IKB_5tX6yIZgRgkpcqFrfVqPTXU' -O mnist.npz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oK3YVw9L6KsO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "import httpimport\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.utils.data\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# In this way we can import functions straight from github\n",
        "with httpimport.github_repo('janchorowski', 'nn_assignments', \n",
        "                            module='common', branch='nn18'):\n",
        "     from common.plotting import plot_mat\n",
        "        \n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "def n(t):\n",
        "    return t.detach().cpu().numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgPW5BAIuQ1_",
        "colab_type": "text"
      },
      "source": [
        "# Problem 1: Prepare the Data\n",
        "\n",
        "The assignments use small, toy datasets. These could be stored entirely in the GPU memory. Below we load the `MNIST` dataset using the `InMemDataLoader` class.\n",
        "\n",
        "As a quick warm-up:\n",
        "1. Implement a generator of an artificial `Barcode` dataset of $4\\times 4$ rectangular images, each with a single white vertical bar on a black background.\n",
        "  * Make sure to add a small amount of Gaussian noise.\n",
        "  * Although the training will be unsupervised, save aside a vector of labels (positions of white strips). We will use them during analysis of model behavior.\n",
        "2. Generate train (10000) and test (1000) sets and wrap them using `InMemDataLoader`.\n",
        "3. Print sample barcodes.\n",
        "\n",
        "<img src=\"data:image/png;base64,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\n",
        "\" />"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eAjC1kA6RR8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InMemDataLoader(object):\n",
        "    \"\"\"A dataloader that serves all data from GPU memory.\"\"\"\n",
        "    __initialized = False\n",
        "    def __init__(self, tensors, batch_size=1, shuffle=False, sampler=None,\n",
        "                 batch_sampler=None, drop_last=False):\n",
        "        \"\"\"A torch dataloader that fetches data from memory.\"\"\"\n",
        "        tensors = [torch.tensor(tensor) for tensor in tensors]\n",
        "        dataset = torch.utils.data.TensorDataset(*tensors)\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.drop_last = drop_last\n",
        "        \n",
        "        if batch_sampler is not None:\n",
        "            if batch_size > 1 or shuffle or sampler is not None or drop_last:\n",
        "                raise ValueError('batch_sampler option is mutually exclusive '\n",
        "                                 'with batch_size, shuffle, sampler, and '\n",
        "                                 'drop_last')\n",
        "            self.batch_size = None\n",
        "            self.drop_last = None\n",
        "\n",
        "        if sampler is not None and shuffle:\n",
        "            raise ValueError('sampler option is mutually exclusive with '\n",
        "                             'shuffle')\n",
        "            \n",
        "        if batch_sampler is None:\n",
        "            if sampler is None:\n",
        "                if shuffle:\n",
        "                    sampler = torch.utils.data.RandomSampler(dataset)\n",
        "                else:\n",
        "                    sampler = torch.utils.data.SequentialSampler(dataset)\n",
        "            batch_sampler = torch.utils.data.BatchSampler(sampler, batch_size, drop_last)\n",
        "\n",
        "        self.sampler = sampler\n",
        "        self.batch_sampler = batch_sampler\n",
        "        self.__initialized = True\n",
        "    \n",
        "    def __setattr__(self, attr, val):\n",
        "        if self.__initialized and attr in ('batch_size', 'sampler', 'drop_last'):\n",
        "            raise ValueError('{} attribute should not be set after {} is '\n",
        "                             'initialized'.format(attr, self.__class__.__name__))\n",
        "\n",
        "        super(InMemDataLoader, self).__setattr__(attr, val)\n",
        "\n",
        "    def __iter__(self):\n",
        "        for batch_indices in self.batch_sampler:\n",
        "            yield self.dataset[batch_indices]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.batch_sampler)\n",
        "    \n",
        "    def to(self, device):\n",
        "        self.dataset.tensors = tuple(t.to(device) for t in self.dataset.tensors)\n",
        "        return self"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBe9-bJwzCJV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with np.load('mnist.npz') as data:\n",
        "    mnist_full_train_data = data['train_data'].astype('float32') / 255.0\n",
        "    mnist_full_train_labels = data['train_labels']\n",
        "    mnist_test_data = data['test_data'].astype('float32') / 255.0\n",
        "    mnist_test_labels = data['test_labels']\n",
        "    \n",
        "    train_data = data['train_data'][:, None, :, :]\n",
        "    test_data = data['test_data'][:, None, :, :]\n",
        "\n",
        "mnist_train_loader = InMemDataLoader(\n",
        "    (train_data.astype('long'), ), \n",
        "    batch_size=50, shuffle=True)\n",
        "\n",
        "mnist_test_loader = InMemDataLoader(\n",
        "    (test_data.astype('long'), ), \n",
        "    batch_size=100, shuffle=True)\n",
        "\n",
        "batch_x, = next(iter(mnist_train_loader))\n",
        "plot_mat(batch_x.numpy(), cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4z-JGb5NzCAC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gen_bars(n):\n",
        "    data = \n",
        "    # TODO: Fill in the missing code\n",
        "    #   - generate a (n, 1, 4, 4) tensor of barcodes\n",
        "    #   - add gaussian noise\n",
        "    #   - ensure pixel intensity values are in [0, 255]\n",
        "    #\n",
        "    return data, labels\n",
        "\n",
        "bar_train_loader = InMemDataLoader(\n",
        "    #\n",
        "    # TODO: Fill in the missing code\n",
        "    #\n",
        ")\n",
        "\n",
        "bar_test_loader = InMemDataLoader(\n",
        "    #\n",
        "    # TODO: Fill in the missing code\n",
        "    #\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWwi1Z1dzBzP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_x, = next(iter(bar_train_loader))\n",
        "plot_mat(batch_x.numpy(), cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MW8EQCibze3R",
        "colab_type": "text"
      },
      "source": [
        "# Problem 2: Masked Convolutions\n",
        "\n",
        "PixelCNN uses masked convolutions to prohibit the model from looking into \"future\" pixels. These can be trivially implemented with `pytorch` by passing a mask tensor to an ordinary conv layer.\n",
        "<center><img src=\"data:image/png;base64,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\n",
        "\" />\n",
        "</center>\n",
        "\n",
        "1. Implement a `MaskedConv2D` layer. The data has a single grayscale channel, so the masking is simplified. It should be able to work in one of two masking modes:\n",
        "  * (A) in which the central pixel cannot access its previous value,\n",
        "  * (B) in which the central pixel can access its previous value.\n",
        "\n",
        "<center><img src=\"data:image/png;base64,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\n",
        "\" /></center>\n",
        "\n",
        "2. For a $k\\times k$ kernel, MaskedConv2D with the above mask performs $O(k^2)$ unnecessary operations (for a single channel). This can be easily reduced to $O(k)$. *Hint: carefully study parameters of [nn.conv2d](https://pytorch.org/docs/stable/nn.html#conv2d).*\n",
        "3. Verify that your conv layers work correctly by plotting their receptive fields. Instead of tracing how the signal propagates from neighboring pixel inwards to a specific location, you can equivalently propagate it outwards from a pixel to the neighboring locations:\n",
        "  * Let your image be a white square $25\\times 25$ pixels with a single black pixel in the middle at $(12, 12)$ (0-indexed).\n",
        "  * Apply a $5\\times 5$ convolution (mask A) with kernel weights set to $1.0$; replace the image with your feature map.\n",
        "  * Apply a similar convolution (mask B) a few times, every time replacing the image with the generated feature map.\n",
        "  * Every subsequent application should extend the shaded area, which started as the single pixel. This is the receptive field.\n",
        "\n",
        "For more details consult the PixelRNN paper: [van den Oord et al., Pixel recurrent neural networks](http://proceedings.mlr.press/v48/oord16.pdf) ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRN1Hrbqtxv1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MaskedConv2D(nn.Conv2d):\n",
        "    \"\"\"\n",
        "    A convolution that masks pixels which ignores pixel below and to the right.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, dilation=1,\n",
        "                 kind='A', bias=True,):\n",
        "        assert kernel_size % 2 == 1\n",
        "        K2 = kernel_size // 2 + 1\n",
        "        K = kernel_size\n",
        "        super(MaskedConv2D, self).__init__(\n",
        "            in_channels, out_channels, (kernel_size//2 + 1, kernel_size), \n",
        "            bias=bias, stride=1, padding=0, dilation=dilation)\n",
        "        #\n",
        "        # TODO: Fill in the missing code\n",
        "        #\n",
        "        self.register_buffer('mask', mask)\n",
        "\n",
        "    def forward(self, input):\n",
        "        \"\"\"\n",
        "        Input is N x C x H x W\n",
        "        \"\"\"\n",
        "        dil_h, dil_w = self.dilation\n",
        "        pad_h = (self.weight.size(-2) - 1) * dil_h\n",
        "        pad_w = (self.weight.size(-1) // 2) * dil_w\n",
        "        input = F.pad(input, [pad_w, pad_w, pad_h, 0])\n",
        "        #\n",
        "        # TODO: Fill in the missing code\n",
        "        #"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2GXfVw0rKj_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_receptive_field(img, subplot_args):\n",
        "    plt.subplot(*subplot_args)\n",
        "    plt.imshow(img[0,0].detach().cpu(), cmap='Greys')\n",
        "    plt.colorbar()\n",
        "    plt.plot([img.size(-2)//2], [img.size(-1)//2], 'x', c='red')\n",
        "\n",
        "def plot_conv_receptive_field(img, mask_kinds):\n",
        "    nrows = (len(mask_kinds) + 4 - 1) // 4\n",
        "    ncols = (len(mask_kinds) + nrows) // nrows\n",
        "    plt.figure(figsize=(ncols*3, nrows*3))\n",
        "    plot_receptive_field(img, (nrows, ncols, 1))\n",
        "    plt.title('Original image')\n",
        "    for i, kind in enumerate(mask_kinds):\n",
        "        #\n",
        "        # TODO: Fill in the missing code\n",
        "        #\n",
        "        plot_receptive_field(img, (nrows, ncols, 2 + i))\n",
        "        plt.title(f'Image after conv{i} (mask {kind})')\n",
        "\n",
        "img = torch.zeros(1, 1, 25, 25)\n",
        "img[0, 0, 25//2, 25//2] = 1.0\n",
        "plot_conv_receptive_field(img, 'A')\n",
        "plot_conv_receptive_field(img, 'BBBBB')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16Fyzb_nrOEW",
        "colab_type": "text"
      },
      "source": [
        "# Problem 3: The Model\n",
        "\n",
        "Start building up the PixelCNN model from its core elements.\n",
        "\n",
        "1. Implement a `SimplePixelCNN` as a stack of `MaskedConv2d` layers. Make sure that you correctly apply type A and B masks,\n",
        "2. Implement a `ResidualPixelCNN` which adds residual connections as described in the paper.\n",
        "3. Train models on the `Barcode` dataset. Feel free to use/modify the training loop provided below. Plot and investigate (i.e., look intensively at) samples generated from the model during training.\n",
        "  * PixelCNN outputs discreete pixel intensity values. Compare samples for the model trained with different numbers of (grayscale) output colors. Be sure to check $c=2$ and $c=256$ output colors. How do they influence the generated samples?\n",
        "4. Alter the `Barcode` dataset so that one bar location (e.g., the rightmost bar) would be more probable than the others. Quickly train an auxiliary classifier to recognize the position of the bar. Do the generated samples match this property of the data?\n",
        "5. Train models with bias terms added to the first conv layer:\n",
        "  * a bias for every channel,\n",
        "  * a bias added to every (channel, pixel). How do they influence the quality and frequency of generated samples? Why?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmcZtSJ16bHk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SimplePixelCNN(nn.Module):\n",
        "    def __init__(self, n_layers, kernel_size,\n",
        "                 hid_channels, out_levels,\n",
        "                 activation=nn.ReLU):\n",
        "        in_channels = 1  # We only support single channel inputs\n",
        "        super(SimplePixelCNN, self).__init__()\n",
        "        self.out_levels = out_levels\n",
        "        self.layers = nn.Sequential()\n",
        "        #\n",
        "        # TODO: Fill in the missing code\n",
        "        #\n",
        "    \n",
        "    def forward(self, input):\n",
        "        \"\"\"\n",
        "        input has shape N x 1 x W x H\n",
        "        output has shape N x out_levels x W x H\n",
        "        \"\"\"\n",
        "        return self.layers(input)\n",
        "\n",
        "\n",
        "class ResidualPixelCNN(nn.Module):\n",
        "    def __init__(self, n_layers=7, out_n_layers=2, hid_channels=32, out_levels=256,\n",
        "                 in_kernel_size=7, kernel_size=3, in_bias_size=1):\n",
        "        in_channels = 1  # We only support single channel inputs\n",
        "        super(ResidualPixelCNN, self).__init__()\n",
        "        self.out_levels = out_levels\n",
        "        \n",
        "        # Add an additional bias (only to the output of the first convolution)\n",
        "        # This bias should be either per channel, or per (channel, pixel).\n",
        "        self.bias = nn.Parameter(\n",
        "            #\n",
        "            # TODO: Fill in the missing code\n",
        "            #\n",
        "        )\n",
        "\n",
        "        #\n",
        "        # TODO: Fill in the missing code\n",
        "        #\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        input has shape N x 1 x W x H\n",
        "        output has shape N x out_levels x W x H\n",
        "        \"\"\"\n",
        "        res = self.in_to_res(x) + self.bias\n",
        "        #\n",
        "        # TODO: Fill in the missing code\n",
        "        #\n",
        "        return res\n",
        "\n",
        "      \n",
        "def plot_samples(h, w, out_levels, figsize=(2,4)):\n",
        "    img = torch.zeros(8, 1, h, w).cuda().requires_grad_(False)\n",
        "\n",
        "    for r in range(h):\n",
        "        for c in range(w):\n",
        "            logits = model(img)     \n",
        "            values = torch.multinomial(torch.softmax(logits[:, :, r, c], 1), 1)\n",
        "            img[:, 0, r, c] = values.float().squeeze(1) / (out_levels - 1)\n",
        "    \n",
        "    plt.figure(figsize=figsize)\n",
        "    plot_mat(img.detach().cpu().numpy(), scaleIndividual=False, cmap='viridis')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-F0-F13QLoXP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, train_loader, test_loader, num_epochs=5, lr=5e-3):\n",
        "    try:\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
        "        global_step = 0\n",
        "\n",
        "        model.to('cuda')\n",
        "        train_loader.to('cuda')\n",
        "        test_loader.to('cuda')\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            model.train()\n",
        "            for inum, (batch_x,) in enumerate(train_loader):\n",
        "                targets = batch_x // (256 / model.out_levels)\n",
        "                inputs = targets.float() / (model.out_levels - 1)\n",
        "                global_step += 1\n",
        "                optimizer.zero_grad()\n",
        "                logits = model(inputs)\n",
        "                loss = F.cross_entropy(logits, targets.squeeze(1))\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                loss = loss.item()\n",
        "                \n",
        "                bits_per_pixel =   # TODO: Fill in the missing code\n",
        "                \n",
        "                if global_step and (global_step%100) == 0:\n",
        "                    print(f\"Step: {global_step: 6} | \"\n",
        "                          f\"lr {optimizer.param_groups[0]['lr']: 8.5f} | \"\n",
        "                          f\"loss: {loss: 6.3f} | bits/pixel {bits_per_pixel: 6.3f}\")\n",
        "\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                plot_samples(batch_x.size(2), batch_x.size(3), model.out_levels)\n",
        "                tot_loss = 0\n",
        "                tot_examples = 0\n",
        "                for (batch_x,) in test_loader:\n",
        "                    targets = batch_x // (256 / model.out_levels)\n",
        "                    inputs = targets.float() / (model.out_levels - 1)\n",
        "                    logits = model(inputs)\n",
        "                    tot_loss += F.cross_entropy(logits, targets.squeeze(1)).item() * batch_x.size(0)\n",
        "                    tot_examples += batch_x.size(0)\n",
        "                loss = tot_loss / tot_examples\n",
        "\n",
        "                bits_per_pixel =   # TODO: Fill in the missing code\n",
        "                \n",
        "                print(f\"Epoch {epoch: 3} ended. Test loss: {loss: 6.3f} | \"\n",
        "                      f\"bits/pixel {bits_per_pixel: 6.3f}\")\n",
        "                scheduler.step(loss)\n",
        "    except KeyboardInterrupt:  # Handles 'stop' button in the notebook\n",
        "        print('-- training stopped --')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3ae0HEAklqX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train a classifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "#\n",
        "# TODO: Fill in the missing code\n",
        "#\n",
        "classifier = \n",
        "score = \n",
        "print(f'Accuracy: {score*100.0}')\n",
        "\n",
        "p = np.histogram(bar_labels_y, bins=range(5), density=True)[0] * 100.0\n",
        "print('Class distribution in the data: ', ' '.join([f'{v:.2f}%' for v in p]))\n",
        "\n",
        "def class_distribution(model, h=4, w=4, n=1000):\n",
        "    #\n",
        "    # TODO: Fill in the missing code\n",
        "    #\n",
        "    p = \n",
        "    print('Class distribution: ', ' '.join([f'{v:.2f}%' for v in p]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuygWYpTuWkS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: Declare the model and run training\n",
        "model = \n",
        "train(model, bar_train_loader, bar_test_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_as7U4_k8xs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_distribution(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Wm7zKYgCINQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: Run with different parameters. Lather, rinse, repeat.\n",
        "model = \n",
        "train(model, bar_train_loader, bar_test_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdYtdJxpk9jJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_distribution(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0k9dtx5hvWuE",
        "colab_type": "text"
      },
      "source": [
        "# Problem 4: MNIST Training\n",
        "\n",
        "1. Train a `ResidualPixelCNN` model on the `MNIST` dataset (do not aim for the perfect parametrs; a couple minutes of training should yield an interesting model).\n",
        "2. Compute and report NLL on `MNIST` train and test sets.\n",
        "3. Implement the remaining improvements to your model, which are described in the PixelCNN paper. Check NLL and the subjective quality of generated samples.\n",
        "  * Gated activations $\\mathbf{y} = tanh(W_{k,f} * \\mathbf{x}) \\odot \\sigma(W_{k,g} * \\mathbf{X})$, where $W_{k,f}$ and $W_{k,g}$ are convolutions producing features and gate weights.\n",
        "  * Horizonal and vertical convolutions, which fully extend the receptive field."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsdjyH6WoVyk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = \n",
        "train(mnist_train_loader, mnist_test_loader, num_epochs=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w29Ybf4H5H5n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GatedMConv2D(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size,\n",
        "                 #cond_channels=(), stride=1, dilation=1, groups=1,\n",
        "                 bias=True, kind='A', act='tanh'):\n",
        "        super(GatedMConv2D, self).__init__()\n",
        "        self.out_chanels = out_channels\n",
        "        self.conv = MaskedConv2D(\n",
        "            in_channels, out_channels * 2, kernel_size, kind=kind,\n",
        "            bias=bias)\n",
        "        self.act = getattr(torch, act)\n",
        "\n",
        "    def forward(self, x):  # , conds):\n",
        "        \"\"\"\n",
        "        x: N x C x T\n",
        "        conds: list of N x CC x T/k\n",
        "        \"\"\"\n",
        "        #\n",
        "        # TODO: Fill in the missing code.\n",
        "        #\n",
        "        \n",
        "      \n",
        "class ResidualGatedPixelCNN(nn.Module):\n",
        "    def __init__(self, num_layers, num_output_layers, kernel_size,\n",
        "                 res_channels, hid_channels, skip_channels, out_levels,\n",
        "                 dropout=0.0, activation=nn.ReLU):\n",
        "        in_channels = 1  # We only support single channel inputs\n",
        "        super(ResidualGatedPixelCNN, self).__init__()\n",
        "        #\n",
        "        # TODO: Fill in the missing code.\n",
        "        #\n",
        "\n",
        "    def forward(self, x): #, conds=()):\n",
        "        \"\"\"\n",
        "        x: BS x Dim x T\n",
        "        conds: list of BS x DimC x T/k\n",
        "        \"\"\"\n",
        "        #\n",
        "        # TODO: Fill in the missing code.\n",
        "        #"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-81IYIU_Ar6",
        "colab_type": "text"
      },
      "source": [
        "# Problem 5: Extras\n",
        "\n",
        "Congratulations for completing the assignments!\n",
        "\n",
        "As an extra exercise, you might either:\n",
        "* Implement one of the recurrent models (RowLSTM or Diagonal BiLSTM) and compare its performance on MNIST with PixelRNN models.\n",
        "* Try training a simple CIFAR-10 model, making sure that your masking handles `RGB` channels properly. Note that training a good model might take quite some GPU time. CIFAR-10 data gets downloaded in the first section of this notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDdoNTmTAQ4Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}